{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3VzcP5d4qVX"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5wHwMEZGZIK"
      },
      "source": [
        "This colab notebook is for the purpose of uploading csv files, inspecting/transforming/concatenating them and for finding the Trigger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_m6gWg2oROj"
      },
      "outputs": [],
      "source": [
        "#Import dependencies\n",
        "\n",
        "import pandas as pd               #Python Data Analysis Library\n",
        "import matplotlib.pyplot as plt   #graphing library\n",
        "import numpy as np\n",
        "import csv\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yFXgZEu1mkv"
      },
      "outputs": [],
      "source": [
        "#Upload dataset/s\n",
        "from google.colab import files\n",
        "\n",
        "answer_var = input('Lokale Datei/n hochladen? (j/n): ')\n",
        "\n",
        "if answer_var == 'j':\n",
        "  uploaded = files.upload()\n",
        "  print('Hochladen abgeschlossen.')\n",
        "elif answer_var == 'n':\n",
        "  # wenn benötigt einfügen\n",
        "  print('Github / Gmail folder upload noch nicht implementiert.')\n",
        "else:\n",
        "  print('Falsche Eingabe!')\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect uploaded dataset/s"
      ],
      "metadata": {
        "id": "i9gdRKWWieOJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p5Xat86e7mJ"
      },
      "outputs": [],
      "source": [
        "filenames = uploaded.keys()   #Dictionary of all uploaded file names\n",
        "column_name = 'Time (us)'     #'Time'\n",
        "column_name2 = 'Voltage (V)'  #'Channel A'                                  \n",
        "filenameiterator = 0        #holds helper var\n",
        "g_nan_counter = 0\n",
        "g_zero_counter = 0\n",
        "\n",
        "answer_var = input('Alle hochgeladenen Dateien inspizieren? (j/n): ')\n",
        "\n",
        "def inspect_file(fn_var):\n",
        "  df_inspect = pd.read_csv(fn_var, sep=',', decimal='.',header = None, skiprows = 3, names = [column_name,column_name2]) #sep und decimal anpassung nicht vergessen\n",
        "  \n",
        "  #Lokal die Anzahl der 0 Werte und fehlender Werte bestimmen und zähler erhöhen, sofern nötig\n",
        "  nan_counter = df_inspect[column_name2].isna().sum()\n",
        "  global g_nan_counter\n",
        "  g_nan_counter = g_nan_counter + nan_counter\n",
        "  try:                                                        \n",
        "    zero_counter = df_inspect[column_name2].value_counts(dropna=False)[0]\n",
        "    global g_zero_counter\n",
        "    g_zero_counter = g_zero_counter + zero_counter               \n",
        "  except KeyError:\n",
        "    zero_counter = 0\n",
        "\n",
        "  #Graph Zeichnen\n",
        "  plt.figure(figsize=(20,5),dpi=150)\n",
        "  plt.suptitle(fn_var + ' Anzahl 0 Werte: ' + str(zero_counter) +' ,Anzahl f Werte: ' + str(nan_counter))\n",
        "  plt.plot(df_inspect[column_name2])\n",
        "  plt.xlabel('Samples')\n",
        "  plt.ylabel('Spannung in V')                                 #Osszi trigger bei den Werten Beachten\n",
        "  plt.show()\n",
        "\n",
        "#Entweder alle hochgeladenen Dateien oder nur eine spezifische inspizieren\n",
        "if answer_var == 'j':\n",
        "  for fn in uploaded.keys():                                    \n",
        "    inspected_filename = list(filenames)[filenameiterator]      \n",
        "    inspect_file(inspected_filename)\n",
        "    filenameiterator=filenameiterator+1\n",
        "elif answer_var == 'n':\n",
        "  #.csv am ende nicht vergessen z.B. '20220520-0001.csv'\n",
        "  answer_var2 = input('Bitte spezifische Datei zum inspizieren angeben: ')  \n",
        "  try:\n",
        "    inspect_file(answer_var2)\n",
        "  except FileNotFoundError:\n",
        "    print('Die Datei ' + answer_var2 + ' konnte nicht gefunden werden.')\n",
        "else:\n",
        "  print('Falsche Eingabe!')\n",
        "\n",
        "#Gesamtmenge aller 0 und fehler ausgeben\n",
        "print('Gesamtmenge an 0 Werten: '+ str(g_zero_counter)+' , Gesamtmenge fehlender Werte: '+ str(g_nan_counter))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean uploaded dataset/s"
      ],
      "metadata": {
        "id": "Zj-704MFinR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bereinigen von 0 Werten, fehlenden Werten und ausreißern. Seperates speichern in C_filname.csv\n",
        "#Anpassbar durch folgende bools\n",
        "null_values = True\n",
        "missing_values = True\n",
        "outlier_values = True\n",
        "min_outlier_size = 0.0001    #how many lowest quantiles to take\n",
        "max_outlier_size = 0.9999    #how many highest quantiles to take\n",
        "\n",
        "filenames = uploaded.keys() #Dictionary of all uploaded file names                                   \n",
        "filenameiterator = 0        #holds helper var\n",
        "g_cleaned_counter = 0\n",
        "g_nan_counter = 0\n",
        "g_zero_counter = 0\n",
        "g_outlier_counter = 0\n",
        "\n",
        "answer_var = input('Alle hochgeladenen Dateien bereinigen? (j/n): ')\n",
        "\n",
        "def clean_file(fn_var):\n",
        "  df_clean = pd.read_csv(fn_var, sep=';', decimal=',',header = None, skiprows = 3, names = ['Time','Channel A']) #sep und decimal anpassung nicht vergessen\n",
        "  \n",
        "  #Anzahl der fehlenden Werte bestimmen und beheben\n",
        "  if null_values == True:\n",
        "    nan_counter = df_clean['Channel A'].isna().sum()\n",
        "    df_clean['Channel A'].fillna(0, inplace=True)\n",
        "    global g_nan_counter\n",
        "    g_nan_counter = g_nan_counter + nan_counter\n",
        "\n",
        "  #Anzahl der 0 Werte bestimmen und beheben\n",
        "  if missing_values == True:\n",
        "    try:                                                        \n",
        "      zero_counter = df_clean['Channel A'].value_counts(dropna=False)[0]\n",
        "      global g_zero_counter\n",
        "      g_zero_counter = g_zero_counter + zero_counter\n",
        "      for z in range(df_clean['Channel A'].size):\n",
        "        if df_clean.at[z,'Channel A'] == 0:\n",
        "          df_clean.at[z,'Channel A'] = df_clean.at[z-1,'Channel A']\n",
        "    except KeyError:\n",
        "      zero_counter = 0\n",
        "\n",
        "  #Anzahl der ausreißer bestimmen und beheben\n",
        "  if outlier_values == True:\n",
        "    outlier_counter = 0\n",
        "    min_threshold, max_threshold = df_clean['Channel A'].quantile([min_outlier_size,max_outlier_size])\n",
        "    #print(df_clean[df_clean['Channel A']>max_threshold])\n",
        "    #print(df_clean[df_clean['Channel A']<min_threshold])\n",
        "    for y in range(df_clean['Channel A'].size):\n",
        "      if df_clean.at[y,'Channel A'] <min_threshold:\n",
        "        df_clean.at[y,'Channel A'] = df_clean.at[y-1,'Channel A']\n",
        "        outlier_counter = outlier_counter + 1\n",
        "      if df_clean.at[y,'Channel A'] >max_threshold:\n",
        "        df_clean.at[y,'Channel A'] = df_clean.at[y-1,'Channel A']\n",
        "        outlier_counter = outlier_counter + 1\n",
        "    global g_outlier_counter\n",
        "    g_outlier_counter = g_outlier_counter + outlier_counter\n",
        "\n",
        "  #Graph Zeichnen\n",
        "  plt.figure(figsize=(20,5),dpi=150)\n",
        "  plt.suptitle(fn_var + ' Null Behoben: ' + str(zero_counter) +' ,Fehlend Behoben: ' + str(nan_counter) + ' ,Ausreißer Behoben: ' + str(outlier_counter))\n",
        "  plt.plot(df_clean['Channel A'])\n",
        "  plt.xlabel('Samples')\n",
        "  plt.ylabel('Spannung in V')                                 #Osszi trigger bei den Werten Beachten\n",
        "  plt.show()\n",
        "\n",
        "  #Graph als seperate csv speichern\n",
        "  f = open('C_' + fn_var, 'w')                     \n",
        "  f.close()\n",
        "  df_clean['Channel A'].to_csv('C_' + fn_var, index=False)\n",
        "\n",
        "\n",
        "#Entweder alle hochgeladenen Dateien oder nur eine spezifische bereinigen\n",
        "if answer_var == 'j':\n",
        "  for fn in uploaded.keys():                                    \n",
        "    inspected_filename = list(filenames)[filenameiterator]      \n",
        "    clean_file(inspected_filename)\n",
        "    filenameiterator=filenameiterator+1\n",
        "elif answer_var == 'n':\n",
        "  #.csv am ende nicht vergessen z.B. '20220520-0001.csv'\n",
        "  answer_var2 = input('Bitte spezifische Datei zum bereinigen angeben: ')  \n",
        "  try:\n",
        "    clean_file(answer_var2)\n",
        "  except FileNotFoundError:\n",
        "    print('Die Datei ' + answer_var2 + ' konnte nicht gefunden werden.')\n",
        "else:\n",
        "  print('Falsche Eingabe!')\n",
        "\n",
        "#Gesamtmenge aller 0 und fehler ausgeben\n",
        "g_cleaned_counter = g_nan_counter + g_outlier_counter + g_nan_counter\n",
        "print('Insgesamt wurden '+ str(g_cleaned_counter)+' Samples bereinigt.')\n"
      ],
      "metadata": {
        "id": "OXoLvjpUmQvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the first trigger and save as the full frame in columns"
      ],
      "metadata": {
        "id": "7qaDnhZmjDxj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3qb8Gxb4Bf2"
      },
      "outputs": [],
      "source": [
        "#Find the first trigger in every uploaded csv and delete all preceding samples. Then save the shortend frames as columns in Full_dataframe_output + date.csv\n",
        "use_cleaned_files = False                        #should the cleaned files be used for finding the trigger\n",
        "smoothingamount = 5                             #how many samples are used to smooth the triggerfinder\n",
        "column_name = 'Time (us)'     #'Time'\n",
        "column_name2 = 'Voltage (V)'  #'Channel A'\n",
        "column_seperator = ','        #';'\n",
        "column_decimal = '.'          #',' \n",
        "triggerfall_threshold = 15                      #threshold to find falling trigger in % downturn\n",
        "max_trigger_search_range = 5000                 #how many samples should be checked for the trigger\n",
        "output_filename = '301-500_Full_dataframe_113'\n",
        "\n",
        "filenames = uploaded.keys()                     #Dictionary of all uploaded file names\n",
        "filenameiterator = 0                            #holds helper var\n",
        "thresholdvar = 0                                #holds helper var\n",
        "\n",
        "f = open(str(output_filename + '.csv'), 'w')                     \n",
        "f.close()\n",
        "\n",
        "for fn in uploaded.keys():                                  #for schleife auskommentieren wenn nicht alle bearbeitet werden sollen          \n",
        "  if use_cleaned_files == False:\n",
        "    str_filename = list(filenames)[filenameiterator]\n",
        "    df_smooth = pd.read_csv(str_filename, sep=column_seperator, decimal=column_decimal,header = None, skiprows = 3, names = [column_name,column_name2]) #sep und decimal anpassung nicht vergessen\n",
        "    df_triggerframe = pd.read_csv(str_filename, sep=column_seperator, decimal=column_decimal,header = None, skiprows = 3, names = [column_name,column_name2])  \n",
        "  else:\n",
        "    str_filename = 'C_'+list(filenames)[filenameiterator]\n",
        "    df_smooth = pd.read_csv(str_filename, sep=column_seperator, decimal=column_decimal,header = None, skiprows = 1, names = [column_name2]) #sep und decimal . statt komma\n",
        "    df_triggerframe = pd.read_csv(str_filename, sep=column_seperator, decimal=column_decimal,header = None, skiprows = 1, names = [column_name2]) \n",
        "\n",
        "  for y in range(max_trigger_search_range):                                               #Trigger in search range suchen, zeilen löschen die geringer als ave_low_voltage sind\n",
        "    \n",
        "    for z in range(smoothingamount):\n",
        "      thresholdvar = thresholdvar + df_triggerframe.at[y+z,column_name2]\n",
        "\n",
        "    thresholdvar = df_triggerframe.at[y,column_name2]-(thresholdvar/smoothingamount)\n",
        "    #print(thresholdvar)\n",
        "    if thresholdvar/df_triggerframe.at[y,column_name2]<1/triggerfall_threshold:\n",
        "      df_triggerframe.drop([y],inplace = True)\n",
        "    else:\n",
        "      df_triggerframe.reset_index(drop=True, inplace=True)                                #reassign index to triggerframe\n",
        "      break\n",
        "\n",
        "  plt.figure(figsize=(20,5),dpi=150)\n",
        "  plt.plot(df_triggerframe[column_name2])\n",
        "  plt.xlabel('Samples')\n",
        "  plt.ylabel('Spannung in V')                                                             #Osszi trigger bei den Werten Beachten\n",
        "  plt.show()\n",
        "\n",
        "  if filenameiterator==0:                                                                 #Daten der ersten csv im output sichern  \n",
        "    df_triggerframe[column_name2].to_csv(str(output_filename + '.csv'), index=False)\n",
        "  else:                                                                                   #Daten der folgenden csv's an die output csv als neue spalten anhängen \n",
        "    csv_append = pd.read_csv(str(output_filename + '.csv'))\n",
        "    csv_append.insert(filenameiterator, column_name2+' Aufnahme:'+str(filenameiterator+1), df_triggerframe[column_name2], True)\n",
        "    csv_append.to_csv(str(output_filename + '.csv'), index=False)\n",
        "\n",
        "  thresholdvar = 0\n",
        "  filenameiterator=filenameiterator+1                                                     #iterator zum lesen der nächste csv erhöhen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find all 0 bits and save as columns"
      ],
      "metadata": {
        "id": "w8Eu3OyhjMIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find all 0 bits, Then save them as columns in 0_bit_output + date.csv\n",
        "bit_size = 249                #how many samples represent a bit\n",
        "bit_difference_size = 7       #how far apart should min and max values of a frame be to count as 0 or 1\n",
        "column_name = 'Time (us)'     #'Time'\n",
        "column_name2 = 'Voltage (V)'  #'Channel A'\n",
        "column_seperator = ','        #';'\n",
        "column_decimal = '.'          #','\n",
        "zero_bits_per_file = 100      #how many zero bits should be in a file before a new one starts\n",
        "increased_bit = 34.6          #ab welchem wert zählt ein 0 bit als gesteigert, setting nicht vergessen!\n",
        "\n",
        "output_filename = '113_0_bit_output_mx_(301-500)_'\n",
        "input_filename = '301-500_Full_dataframe_113' + '.csv'  \n",
        "\n",
        "#holds helper var                          \n",
        "first_append = True\n",
        "filecounter = 0\n",
        "sample_counter = 0\n",
        "total_bit_counter = 0\n",
        "\n",
        "#load input file\n",
        "df_input = pd.read_csv(input_filename, sep=column_seperator, decimal=column_decimal)\n",
        "\n",
        "#go through each coloumn of the input file\n",
        "for fn in range(len(df_input.columns)):\n",
        "  str_column_name = list(df_input)[fn]\n",
        "  df_0_bit_finder = pd.DataFrame(data=df_input[str_column_name], columns=[str_column_name])\n",
        "  df_bit_size_frame = pd.DataFrame(index=range(bit_size),columns=[str_column_name])\n",
        "  #go through a row and save as new column when bit_size is reached\n",
        "  for fs in range(df_0_bit_finder[str_column_name].size):\n",
        "    df_bit_size_frame.at[sample_counter,str_column_name] = df_0_bit_finder.at[fs,str_column_name]\n",
        "    sample_counter = sample_counter + 1\n",
        "    #if sample size is reached, start writing in a column\n",
        "    if sample_counter > bit_size:\n",
        "      #get min and max values to differentiate between 1 and 0 bits\n",
        "      minvalue = df_bit_size_frame[str_column_name].min()\n",
        "      maxvalue = df_bit_size_frame[str_column_name].max()\n",
        "      if maxvalue-minvalue > bit_difference_size:\n",
        "\n",
        "        #WICHTIG!!!\n",
        "        #if maxvalue < increased_bit:  #sollen nur sich nicht steigernde 0 bits gespeichert werden?\n",
        "        if maxvalue > increased_bit: #sollen nur gesteigerte 0 bits gespeichert werden?\n",
        "        #SETTING!!! beide auskommentieren für mixed bits oder EINES an je nachdem was gespeichert werden soll\n",
        "\n",
        "          if first_append == True:\n",
        "            f = open(output_filename + str(filecounter) + '.csv', 'w')                    \n",
        "            f.close()\n",
        "            df_bit_size_frame.to_csv(output_filename + str(filecounter) + '.csv', index=False)\n",
        "            first_append = False\n",
        "          else:\n",
        "            csv_append = pd.read_csv(output_filename + str(filecounter) + '.csv')\n",
        "            csv_append.insert(total_bit_counter,str_column_name+' bit:'+ str(total_bit_counter), df_bit_size_frame[str_column_name], True)\n",
        "            csv_append.to_csv(output_filename + str(filecounter) + '.csv', index=False)\n",
        "            sample_counter = 0\n",
        "            total_bit_counter = total_bit_counter+1\n",
        "            #initiate writing of new file in the next loop if zero bit per file is reached\n",
        "            if total_bit_counter == zero_bits_per_file-1:\n",
        "              sample_counter = 0\n",
        "              filecounter = filecounter+1\n",
        "              total_bit_counter = 0\n",
        "              first_append = True\n",
        "              print('file number:'+ str(filecounter)+' is done.')\n",
        "\n",
        "        else:\n",
        "          sample_counter = 0\n",
        "\n",
        "      else:\n",
        "        sample_counter = 0\n",
        "\n",
        "  #reset helper var for next loop\n",
        "  sample_counter = 0 "
      ],
      "metadata": {
        "id": "2stGLjFoi_l5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}